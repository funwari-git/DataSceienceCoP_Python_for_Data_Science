{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table width=100%; style=\"background-color:#caf0fa\";>\n",
    "    <tr style=\"background-color:#caf0fa\">\n",
    "        <td>\n",
    "            <h1 style=\"text-align:right\">\n",
    "                Python for Data Science Training - Week 3\n",
    "            </h1>\n",
    "        </td>\n",
    "        <td>\n",
    "            <img src=\"../img/jica-logo.png\" alt = \"JICA Training\" style = \"width: 100px;\"/>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "# Today's Contents\n",
    "1. Pandas\n",
    "\n",
    "---\n",
    "\n",
    "# 1. Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Read file\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Read CSV data\n",
    "df = pd.read_csv(csv_file)\n",
    "# Read Excel data\n",
    "df = pd.read_excel(excel_file)\n",
    "# Read Stata file\n",
    "df = pd.read_stata(stata .dta file)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data: [GDP Growth from World Development Indicator](https://data.worldbank.org/indicator/NY.GDP.MKTP.KD.ZG?view=chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access to dataset\n",
    "# `..` means \"Go to the parent folder\"\n",
    "data = 'data/GDP_growth_from_WDI/API_NY.GDP.MKTP.KD.ZG_DS2_en_csv_v2_2252300.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv data\n",
    "df = pd.read_csv(data, header = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first check datatype\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.head()` method gives you the first 5 lines of the dataframe.  \n",
    "`df.tail()` method gives you the last 5 lines of the dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df.columns` allows you to access column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always recommended to find the shape of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .shape method\n",
    "df.shape # (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find length of dataframw with `len()`\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.shape[0]\n",
    "col = df.shape[1]\n",
    "print('Dataframe\\'s shape is {row} and {col}'.format(row = row, col = col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus on the last 6 years (2015-2020).  \n",
    "Selecting specific columns can be implemented as below:\n",
    "\n",
    "```python\n",
    "new_df = df[[col1, col2, col3, ...]]\n",
    "```\n",
    "or, this can be much simpler by writing:\n",
    "```python\n",
    "selected_cols = [col1, col2, col3,...]\n",
    "new_df = df[selected_cols]\n",
    "```\n",
    "In Python, using `[ ]` is called *indexing*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do it\n",
    "cols = ['Country Name', 'Country Code','2015', '2016', '2017', '2018', '2019', '2020']\n",
    "selected_df = df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's call `.head()` method again.\n",
    "selected_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find basic statistics of the data  \n",
    "`df.describe()`\n",
    "\n",
    "This automatically calculates basic statistcis. It ignores columns with string type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize this! -> We'll cover visualization next week!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "selected_df.describe().T[['mean']].plot(kind = 'line')\n",
    "plt.title('GDP Growth Global Average'); plt.ylabel('Percent');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's access to the individual column.  \n",
    "`df['column_name']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See individual country name\n",
    "selected_df['Country Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding unique value\n",
    "selected_df['Country Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the number of unique value\n",
    "selected_df['Country Name'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with Null value.  \n",
    "Finding null value is `df.isnull()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful by adding `sum()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage can be cauculated by simply deviding with df length.\n",
    "selected_df.isnull().sum() / len(selected_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to show them by multiplying by 100, just do it with `* 100`.\n",
    "selected_df.isnull().sum() / len(selected_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's drop the column of 2020 with `.drop` method\n",
    "# In Python, axis = 0 is row wise, axis = 1 is column wise\n",
    "selected_df = selected_df.drop(columns = ['2020'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Null value\n",
    "1. drop null value\n",
    "2. Fill value - median, mean, forward, backward methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null value\n",
    "selected_df_drop = selected_df.dropna(subset = ['2019'])\n",
    "\n",
    "# Let's check how many were dropped.\n",
    "print('Before:\\t', len(selected_df))\n",
    "print('After:\\t', len(selected_df_drop))\n",
    "print('Dropped:\\t', (len(selected_df) - len(selected_df_drop)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df_drop.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この時点でNull valueはゼロですが、以下に参考までにNull valueがあった場合のFillの方法をお伝えしておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill value\n",
    "# by median value\n",
    "median_value = selected_df_drop['2015'].median()\n",
    "print('2015 median value: ', median_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null value by fillna method\n",
    "selected_df_drop['2015'].fillna(value = median_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by forward fill\n",
    "selected_df_drop.fillna(method = 'ffill', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by backward fill\n",
    "selected_df_drop.fillna(method = 'bfill', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df_drop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Two dataset\n",
    "A very friendly method with Python is data merge, which can be done with `.merge`, `.join`, `.concatenate`. We'll use `.merge` method. For more details, take a look at [this pandas tutorial](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html).\n",
    "<br>\n",
    "<br>\n",
    "Let's import another file that contains country classification taken from [here](https://datahelpdesk.worldbank.org/knowledgebase/articles/906519-world-bank-country-and-lending-groups)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = pd.read_excel('data/WB_country_classification.xls', sheet_name = 'List of economies', header = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting with .loc and .iloc\n",
    "Select a single row and column\n",
    "- `.loc`: `df.loc[row_label, col_label]` \n",
    "- `.iloc`: `df.iloc[row_index, col_index]`  \n",
    "\n",
    "Select multiple rows and columns\n",
    "- `.loc`: `df.loc[row_label_start:row_label:end, col_label_start:col_label_end]`\n",
    "- `.iloc`: `df.loc[row_index_start:row_index:end, col_index_start:col_index_end]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.loc[1, 'Economy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.loc[1, 'Region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.loc[1, ['Economy', 'Region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.loc[1, 'Economy':'Lending category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.loc[1, 'Economy':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.loc[1, :'Lending category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.loc[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .iloc\n",
    "df_class.iloc[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.iloc[1, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.iloc[1:4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframe\n",
    "## .loc[1:, [column_name]] is to select row from line 1, and to select columns.\n",
    "## .reset_index is to reset index number.\n",
    "df_class = df_class.loc[1:, ['Economy', 'Code', 'Region', 'Income group']].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's trim rows after world.\n",
    "df_class = df_class.iloc[:265, :]\n",
    "df_class.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check null values\n",
    "df_class.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding which values are null in the \"Code\" column.\n",
    "df_class[df_class['Code'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class = df_class.drop(index = [218, 219], axis = 0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate Null value of the Region column\n",
    "df_class[df_class['Region'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class[df_class['Income group'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, looks like null values of Region and Income group are regional data. Let's drop them.\n",
    "df_class = df_class.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two dataframes: `selected_df_drop` and `df_class`. One important element is with which **key** is to be used for joining the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GDP dataframe: ', sorted(selected_df_drop['Country Code'])[:10])\n",
    "print('\\nCountry class dataframe: ', sorted(df_class['Code'])[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the country code is good to go. Let's merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(selected_df_drop, df_class, how = 'inner', left_on = 'Country Code', right_on = 'Code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(columns = ['Economy','Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.shape)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà!! You've well done to merge datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a quick investigation.\n",
    "merged_df['Income group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also find percent\n",
    "merged_df['Income group'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly look at region\n",
    "merged_df['Region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['Region'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groupby\n",
    "It would be more interesting if we could aggregate GDP growth at a regional/income level. Let's do it with `.groupby` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df = merged_df.groupby('Region').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_and_income_df = merged_df.groupby(['Region', 'Income group']).mean()\n",
    "region_and_income_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's deep dive into Africa\n",
    "africa_df = merged_df[merged_df['Region'] == 'Sub-Saharan Africa'].reset_index(drop = True)\n",
    "\n",
    "# find major statistics in 2015 and 2019\n",
    "africa_group_df = africa_df.groupby(['Income group']).agg({'2015':['mean', 'max', 'min', 'median'],\n",
    "                                                          '2019':['mean', 'max', 'min', 'median']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_group_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a downward trend in high income, while lower income is an upward trend. Let's go back to the countries in each classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_df[africa_df['Income group'] == 'High income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_df[africa_df['Income group'] == 'Low income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How is the trend if we would make a binary income category.\n",
    "africa_df['Income group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_class_list = []\n",
    "for element in africa_df['Income group']:\n",
    "    if element == 'High income':\n",
    "        binary_class = 'upper_category'\n",
    "        \n",
    "    elif element == 'Upper middle income':\n",
    "        binary_class = 'upper_category'  \n",
    "        \n",
    "    elif element == 'Lower middle income':\n",
    "        binary_class = 'lower_category'\n",
    "        \n",
    "    elif element == 'Low income':\n",
    "        binary_class = 'lower_category'\n",
    "        \n",
    "    binary_class_list.append(binary_class)\n",
    "        \n",
    "africa_df['binary_class'] = binary_class_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_df['binary_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_df.groupby('binary_class').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "africa_df.groupby('binary_class').mean().T.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JICA_training",
   "language": "python",
   "name": "jica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
